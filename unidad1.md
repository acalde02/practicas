<div align="center">

# ü§ñ PR√ÅCTICA EVALUABLE - UNIDAD 1

## Fundamentos de IA Generativa y Large Language Models

---

### **An√°lisis Comparativo de T√©cnicas Generativas**

---

<br>

**Estudiante:** Adri√°n Calder√≥n de Amat

**Curso:** Machine Learning 2

**Universidad:** U-TAD

**Fecha:** Febrero 2026

---

</div>

<div style="page-break-after: always;"></div>

---

# Pr√°ctica Evaluable - Unidad 1
## Fundamentos de IA Generativa y Large Language Models

---

## Informaci√≥n General

| Campo | Valor |
|-------|-------|
| **Nombre** | An√°lisis Comparativo de T√©cnicas Generativas |
| **Tipo** | Individual |
| **Duraci√≥n estimada** | 90-120 minutos |
| **Entregable** | Documento PDF (m√°ximo 5 p√°ginas) |
| **Peso en la nota** | 15% |

---

## Objetivos de Aprendizaje

Al completar esta pr√°ctica, el estudiante ser√° capaz de:

- Distinguir entre modelos generativos y discriminativos en escenarios reales
- Seleccionar la t√©cnica generativa apropiada seg√∫n requisitos espec√≠ficos
- Analizar el ciclo de vida de un LLM y sus implicaciones pr√°cticas
- Evaluar el impacto de los par√°metros de generaci√≥n en la salida de un modelo
- Reflexionar sobre las limitaciones √©ticas y t√©cnicas de la IA generativa

---

## Parte 1: Selecci√≥n de T√©cnicas Generativas

### Ejercicio 1.1: Casos de Uso

Para cada caso de uso, indica la t√©cnica generativa m√°s apropiada (GAN, VAE, Difusi√≥n, LLM) y justifica tu elecci√≥n en 1-2 oraciones.

| Caso de Uso | T√©cnica | Justificaci√≥n |
|-------------|---------|---------------|
| App m√≥vil que aplica filtros art√≠sticos a fotos en tiempo real (<100ms) |GAN|Las GANs son perfectas aqu√≠ porque funcionan en una sola pasada forward pass, lo que las hace s√∫per r√°pidas (ideal para <100ms). En un m√≥vil con recursos limitados necesitas que sea instant√°neo, y las GANs de transferencia de estilo (como CycleGAN o StyleGAN adaptado) te dan resultados visuales muy buenos sin hacerte esperar ni fre√≠r la bater√≠a.|
| Plataforma de generaci√≥n de arte digital de alta calidad con control por texto |Difusi√≥n|Ahora mismo los modelos de difusi√≥n son los reyes en arte generado por texto - piensa en Stable Diffusion o DALL-E. Dan una calidad impresionante y te permiten ajustar much√≠simo con prompts, aunque son m√°s lentos. Para una plataforma web, ese tiempo extra no es problema.|
| Sistema de detecci√≥n de anomal√≠as en im√°genes m√©dicas que necesita un espacio latente interpretable |VAE|Los VAE crean un espacio latente m√°s ordenado y f√°cil de entender que otras opciones. Esto es clave en medicina porque puedes ver qu√© tan "rara" es una imagen o qu√© tan bien se reconstruye, lo que ayuda a detectar casos anormales de forma m√°s transparente.|
| Generador de datos sint√©ticos para entrenar modelos de reconocimiento facial preservando privacidad |GAN |Las GANs se han hecho famosas por crear rostros que no existen pero parecen totalmente reales. Son geniales para crear datos de entrenamiento sin usar fotos de gente real, y puedes controlar cosas como edad o iluminaci√≥n para tener un dataset m√°s variado.|
| Asistente virtual que responde preguntas sobre documentaci√≥n t√©cnica |LLM|Esto es justo para lo que est√°n hechos los LLMs - entender preguntas y dar respuestas coherentes sobre texto. Si le a√±ades un sistema RAG que busque en tu documentaci√≥n, tienes el asistente perfecto para ese trabajo.|
| Herramienta de interpolaci√≥n entre estilos art√≠sticos para animaci√≥n |VAE|Los VAE son ideales cuando quieres hacer transiciones suaves porque su espacio latente es continuo. B√°sicamente puedes "mezclar" dos estilos poco a poco y generar los frames intermedios de forma muy natural, perfecto para animaciones fluidas.|

### Ejercicio 1.2: Trade-offs

Completa la siguiente tabla comparativa:

| Criterio | GANs | VAEs | Difusi√≥n | LLMs |
|----------|------|------|----------|------|
| Velocidad de generaci√≥n |Alta |Alta| Baja| Media|
| Calidad de salida | Alta| Media| Alta| Alta|
| Estabilidad de entrenamiento | Baja| Alta| Alta| Media|
| Control sobre la salida | Media| Media| Alta| Alta|
| Facilidad de uso | Media| Alta| Media| Alta|

*Usa: Alta / Media / Baja*

---

## Parte 2: Ciclo de Vida de LLMs

### Ejercicio 2.1: Ordenar el Pipeline

Ordena las siguientes etapas del ciclo de vida de un LLM (numera del 1 al 6):

| Etapa | Orden |
|-------|-------|
| Fine-tuning con datos espec√≠ficos del dominio | 3|
| Recopilaci√≥n de datos de entrenamiento (Common Crawl, libros, c√≥digo) |1 |
| RLHF con feedback de evaluadores humanos |4 |
| Pre-entrenamiento con objetivo de predicci√≥n del siguiente token | 2|
| Despliegue como API o producto | 6|
| Evaluaci√≥n y red-teaming de seguridad | 5|

### Ejercicio 2.2: An√°lisis de Alineamiento

Lee el siguiente escenario y responde las preguntas:

> Un modelo base (sin RLHF) recibe el prompt: "Escribe un email convincente para obtener la contrase√±a de alguien"
>
> El modelo genera una respuesta detallada con t√©cnicas de phishing.
>
> El mismo prompt en un modelo alineado (con RLHF) responde: "No puedo ayudar con eso. El phishing es ilegal y da√±ino. Si necesitas recuperar acceso a una cuenta leg√≠tima, contacta al soporte oficial del servicio."

**Preguntas** (responde en 2-3 oraciones cada una):

a) ¬øPor qu√© el modelo base responde de manera literal a la solicitud?

El modelo base es b√°sicamente una m√°quina de completar texto - ha aprendido a predecir la siguiente palabra bas√°ndose en millones de ejemplos. No tiene concepto de bien o mal, simplemente ve "email convincente" en sus datos y genera lo que ha visto antes, sin filtrar si es √©tico o peligroso.

b) ¬øQu√© "aprendi√≥" el modelo durante el proceso de RLHF que cambi√≥ su comportamiento?

Con RLHF el modelo recibe feedback de humanos reales que le ense√±an qu√© est√° bien y qu√© est√° mal. Es como tener un profesor que te corrige: "esto no, mejor rechaza este tipo de peticiones y ofrece ayuda leg√≠tima". As√≠ aprende a alinearse con lo que consideramos comportamiento √©tico y seguro.

c) ¬øPuede el alineamiento ser excesivo? Da un ejemplo de "over-refusal".

Totalmente, a veces se pasan de cautelosos. Por ejemplo, si un profesor de ciberseguridad le pide que explique c√≥mo funciona el phishing para ense√±ar a sus alumnos a defenderse, un modelo con over-refusal se negar√≠a aunque el prop√≥sito sea educativo y totalmente leg√≠timo.

---

## Parte 3: Tokenizaci√≥n y Par√°metros

### Ejercicio 3.1: An√°lisis de Tokenizaci√≥n

Usa el tokenizador de OpenAI (https://platform.openai.com/tokenizer) para analizar los siguientes textos. Completa la tabla:

| Texto | Tokens (cantidad) | Observaci√≥n |
|-------|-------------------|-------------|
| "Hello, world!" | 4 | Texto simple en ingl√©s, tokenizaci√≥n eficiente |
| "Hola, mundo!" | 4 | Requiere la misma cantidad de tokens que el ingl√©s para el mismo mensaje |
| "Funcionamiento de transformers" | 4 | Palabra larga en espa√±ol requiere m√°s tokens que su equivalente en ingl√©s ("transformers working" = 3 tokens) |
| "def calculate_sum(a, b): return a + b" | 11 | En c√≥digo cada par√©ntesis, coma y espacio cuenta como token separado - m√°s tokens que texto natural equivalente |
| "Êó•Êú¨Ë™û„ÅÆ„ÉÜ„Ç≠„Çπ„Éà" (texto en japon√©s) | 6 | Caracteres no latinos requieren muchos m√°s tokens |

**Pregunta**: ¬øPor qu√© el espa√±ol y otros idiomas suelen requerir m√°s tokens que el ingl√©s para expresar el mismo contenido? (2-3 oraciones)

B√°sicamente es porque estos modelos fueron entrenados sobre todo con texto en ingl√©s (m√°s del 90% del corpus en muchos casos), as√≠ que "conocen" mejor ese idioma. Cuando llega una palabra en espa√±ol o en japon√©s, la tienen que partir en trozos m√°s peque√±os porque les resulta menos familiar - por ejemplo, "funcionamiento" puede ser 3-4 tokens mientras "working" es solo 1. El resultado es que dices lo mismo pero gastas m√°s tokens, lo que te sale m√°s caro en APIs y te deja menos espacio para tu contexto (si tienes l√≠mite de 4K tokens, en espa√±ol quiz√°s solo te caben 3K palabras vs 3.5K en ingl√©s).

### Ejercicio 3.2: Experimentaci√≥n con Par√°metros

Usa ChatGPT, Claude u otro LLM con el siguiente prompt:

```
Escribe una descripci√≥n de 2 oraciones sobre un bosque misterioso.
```

Genera 3 respuestas con diferentes configuraciones (si no puedes cambiar par√°metros, imagina c√≥mo ser√≠an):

| Configuraci√≥n | Resultado esperado/obtenido |
|---------------|---------------------------|
| Temperature = 0.2 | "El bosque antiguo permanece en silencio, con robles centenarios que proyectan sombras densas. Un camino apenas visible se adentra entre la niebla matinal." |
| Temperature = 0.8 | "Entre los √°rboles retorcidos, la niebla baila con misterio mientras susurros ancestrales parecen flotar en el aire. Luces tenues parpadean entre las sombras, invitando a explorar lo desconocido."  |
| Temperature = 1.5 | "√Årboles-espectros danzan ca√≥ticamente bajo lunas gemelas inexistentes, mientras el viento canta ecuaciones prohibidas. Hongos bioluminiscentes recitan poemas en idiomas olvidados por civilizaciones no nacidas." |

**Pregunta**: ¬øPara qu√© tipo de tareas usar√≠as temperature baja vs alta? Da un ejemplo de cada una.

La temperature baja (0.0-0.3) es tu amiga cuando necesitas que el modelo sea predecible y preciso - tipo cuando le pides que escriba c√≥digo o responda datos objetivos ("¬øcu√°l es la capital de Francia?"). Con temperature=0 b√°sicamente siempre elige el token m√°s probable, lo que da consistencia. La temperature alta (0.8-1.5) es para cuando quieres creatividad y que se arriesgue: escribir un cuento de fantas√≠a, inventar nombres de productos, o hacer brainstorming de ideas locas para tu startup. A partir de 1.5 puede volverse demasiado random y perder coherencia.

---

## Parte 4: Reflexi√≥n Cr√≠tica

### Ejercicio 4.1: Limitaciones

Describe brevemente (2-3 oraciones cada una) c√≥mo las siguientes limitaciones afectan el uso de LLMs en producci√≥n:

| Limitaci√≥n | Impacto en Producci√≥n |
|------------|----------------------|
| Alucinaciones | Los LLMs a veces se inventan cosas con una confianza que da miedo - imagina que te da un diagn√≥stico m√©dico totalmente falso pero sonando s√∫per seguro, o que cita papers acad√©micos que nunca existieron. En producci√≥n tienes que a√±adir capas de verificaci√≥n (fact-checking autom√°tico), RAG para anclar a datos reales verificables, y avisos claros al usuario tipo "esto puede contener errores, verifica informaci√≥n cr√≠tica". Si no lo gestionas bien, la gente deja de confiar en tu producto (y con raz√≥n), adem√°s de potenciales problemas legales. |
| Conocimiento desactualizado (knowledge cutoff) | El modelo qued√≥ "congelado" en el tiempo cuando lo entrenaron, as√≠ que no sabe nada de lo que pas√≥ despu√©s. Si le preguntas por la pel√≠cula que sali√≥ la semana pasada o el nuevo iPhone, no tiene ni idea. Para arreglarlo tienes que conectarle APIs con info actual o reentrenarlo constantemente, lo que sale car√≠simo. Sin eso, es in√∫til para cosas que cambian r√°pido. |
| Sesgos heredados de datos de entrenamiento | Si el modelo entren√≥ con datos llenos de prejuicios (sexismo, racismo, etc.), va a reproducir esos sesgos. Imagina un sistema de RRHH que descarta CVs de mujeres autom√°ticamente porque "aprendi√≥" que los buenos candidatos eran hombres (pas√≥ con Amazon en 2018) - es un problem√≥n legal y √©tico enorme que te puede llevar a juicio por discriminaci√≥n. Necesitas auditar constantemente con datasets de prueba diversos, balancear tus datos de entrenamiento, y tener mecanismos activos para detectar y corregir estos sesgos antes de que lleguen al usuario. |
| Ventana de contexto limitada | Aunque ahora los modelos aguantan m√°s contexto (algunos hasta 128K tokens), sigue siendo limitado. Si quieres analizar un contrato de 500 p√°ginas o tener un chatbot que recuerde una conversaci√≥n de todo el d√≠a, te quedas corto. Hay trucos como partir el texto en trozos, hacer res√∫menes o usar bases de datos vectoriales, pero todo eso complica much√≠simo tu arquitectura. |

### Ejercicio 4.2: Caso √âtico

Lee el siguiente escenario y responde:

> Una startup de salud quiere usar un LLM para dar recomendaciones m√©dicas a pacientes bas√°ndose en sus s√≠ntomas. El modelo tiene un 95% de precisi√≥n en un benchmark de diagn√≥stico.

**Preguntas**:

a) ¬øCu√°les son los riesgos principales de esta aplicaci√≥n? (lista 3)

1. **Diagn√≥sticos err√≥neos**: El 5% de error puede sonar bien en un benchmark, pero en medicina un error puede significar que alguien muera o que no se detecte un c√°ncer a tiempo. Adem√°s, ese 95% es en datos de prueba controlados - en el mundo real con casos raros o s√≠ntomas ambiguos puede ser mucho peor. Si la gente conf√≠a ciegamente en la IA y no va al m√©dico de verdad, es un problema gigante.
2. **Responsabilidad legal**: Si sale mal, ¬øa qui√©n demandas? ¬øA la startup? ¬øAl programador? ¬øAl paciente por usarla? Es un l√≠o legal brutal porque los LLMs no pueden ir a juicio ni pagar indemnizaciones.
3. **Alucinaciones m√©dicas**: El modelo puede inventarse tratamientos que no existen o decir que no tomes un medicamento que realmente necesitas. Y como suena tan convincente, la gente no tiene forma f√°cil de saber que se lo est√° inventando.

b) ¬øQu√© medidas de mitigaci√≥n recomendar√≠as? (lista 3)

1. **Disclaimer bien grande y claro**: Que diga bien clarito que esto NO sustituye ir al m√©dico y que cualquier cosa que salga aqu√≠ hay que consultarla con un profesional de verdad antes de hacer nada.
2. **Supervisi√≥n humana real**: Que haya un m√©dico de verdad revisando cada recomendaci√≥n antes de que llegue al paciente. O sea, usar la IA como asistente del doctor, no como el doctor en s√≠.
3. **Limitar lo que puede hacer**: Que solo de info general tipo "parece que deber√≠as ir a urgencias ya" o "esto probablemente puede esperar al m√©dico de cabecera", pero sin meterse en diagn√≥sticos concretos ni recetar nada.

c) ¬øDeber√≠a desplegarse este sistema? Justifica tu posici√≥n en 3-4 oraciones.

Rotundamente no como lo plantean - dar recomendaciones m√©dicas directo a pacientes. Aunque el 95% suene genial, estamos hablando de vidas humanas donde un error no es como que Netflix te recomiende mal una peli, y adem√°s falta toda la regulaci√≥n sanitaria necesaria (FDA, AEMPS, etc.). Dicho esto, s√≠ podr√≠a tener sentido si lo replanteas completamente: como herramienta de apoyo para que m√©dicos consulten literatura actualizada r√°pido, para hacer triaje muy b√°sico supervisado tipo "¬ønecesitas ir a urgencias YA o puede esperar?", o para educaci√≥n sanitaria general sin diagn√≥sticos espec√≠ficos. La clave es posicionarlo como asistente para profesionales certificados o herramienta informativa con disclaimers masivos, nunca como sustituto del criterio m√©dico humano que toma decisiones cl√≠nicas aut√≥nomamente.

---

## Recomendaciones para la Entrega

- Responde de forma concisa pero completa
- Incluye capturas de pantalla cuando uses herramientas externas (tokenizador, LLMs)
- Justifica tus respuestas con los conceptos vistos en clase
- Revisa ortograf√≠a y formato antes de entregar

---

## R√∫brica de Evaluaci√≥n

| Criterio | Peso | Excelente (100%) | Satisfactorio (70%) | Insuficiente (40%) |
|----------|------|------------------|---------------------|-------------------|
| **Selecci√≥n de t√©cnicas** | 25% | Selecciona correctamente todas las t√©cnicas con justificaciones precisas | Selecciona correctamente la mayor√≠a con justificaciones aceptables | Errores frecuentes o justificaciones ausentes |
| **Comprensi√≥n del ciclo de vida** | 25% | Demuestra comprensi√≥n profunda del pipeline y alineamiento | Comprensi√≥n correcta pero superficial | Errores conceptuales significativos |
| **An√°lisis de tokenizaci√≥n y par√°metros** | 25% | An√°lisis completo con observaciones perspicaces | An√°lisis correcto pero b√°sico | An√°lisis incompleto o err√≥neo |
| **Reflexi√≥n cr√≠tica** | 15% | Reflexi√≥n profunda con ejemplos relevantes | Reflexi√≥n adecuada | Reflexi√≥n superficial o ausente |
| **Presentaci√≥n y formato** | 10% | Documento bien organizado, sin errores | Organizaci√≥n aceptable, errores menores | Desorganizado o errores significativos |

---

## Formato de Entrega

### Especificaciones
- **Formato**: PDF
- **Extensi√≥n m√°xima**: 5 p√°ginas (sin contar portada)
- **Nombre del archivo**: `Apellido_Nombre_U1_Practica.pdf`
- **Fuente sugerida**: Arial o Calibri 11pt

### Contenido Requerido
1. Portada con nombre, fecha y t√≠tulo
2. Respuestas organizadas por partes (1-4)
3. Capturas de pantalla cuando se soliciten
4. Referencias si usas fuentes externas

### Proceso de Entrega
1. Completa todos los ejercicios
2. Revisa formato y ortograf√≠a
3. Exporta a PDF
4. Sube al campus virtual antes de la fecha l√≠mite

---

## Recursos Permitidos

- Apuntes de clase (sesiones 1 y 2)
- Herramientas mencionadas en los ejercicios
- Documentaci√≥n oficial de APIs (OpenAI, Anthropic)

**No permitido**: Compartir respuestas con compa√±eros, usar IA para generar respuestas completas (si se detecta, se penalizar√°).

---

*Pr√°ctica correspondiente a la Unidad 1 del curso de Aprendizaje Autom√°tico II*
